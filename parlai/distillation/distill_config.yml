student_config:
  attention_dropout: 0.0
  embedding_size: 512
  ffn_size: 2048
  embeddings_scale: True
  variant: xlm
  n_heads: 16
  n_positions: 512
  n_encoder_layers: 8
  n_decoder_layers: 8
  learn_positional_embeddings: True
  dropout: 0.1
  relu_dropout: 0.0
  activation: gelu
teacher_config:
  attention_dropout: 0.0
  embedding_size: 2560
  ffn_size: 10240
  embeddings_scale: True
  variant: prelayernorm
  n_heads: 32
  n_positions: 128
  n_encoder_layers: 2
  n_decoder_layers: 24
  learn_positional_embeddings: False
  dropout: 0.1
  relu_dropout: 0.0
  activation: gelu